{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq8YSNO7MRhP",
        "outputId": "ae110d3b-dfa7-47cb-b2f7-619afd3c3de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18pI0FdziEH-pm-eyf49dbqI062OYwIrJ\n",
            "From (redirected): https://drive.google.com/uc?id=18pI0FdziEH-pm-eyf49dbqI062OYwIrJ&confirm=t&uuid=e7503d0a-5819-4f4a-989d-8ba557352d55\n",
            "To: /content/yolov5/yolov5/yolov5/yolov5/yolov5/Dataset.zip\n",
            "100%|██████████| 186M/186M [00:02<00:00, 68.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and extracted to 'plastic_dataset' folder.\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gdown\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "file_id = \"18pI0FdziEH-pm-eyf49dbqI062OYwIrJ\"\n",
        "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output_zip = \"Dataset.zip\"\n",
        "\n",
        "gdown.download(download_url, output_zip, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(output_zip, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"plastic_dataset\")\n",
        "\n",
        "print(\"Dataset downloaded and extracted to 'plastic_dataset' folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "_9UTWyplSeZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471c2563-6821-4117-dae2-d5d6aed59cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plastic_dataset contents: ['plastic_annotation', 'plastic_images']\n",
            "plastic_images contents: ['plastic_images']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List all items (including folders and files) in plastic_dataset\n",
        "print(\"plastic_dataset contents:\", os.listdir('plastic_dataset'))\n",
        "\n",
        "# List all items in plastic_images (should show your files/folders)\n",
        "print(\"plastic_images contents:\", os.listdir('plastic_dataset/plastic_images'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "XMr46SSfSeV-"
      },
      "outputs": [],
      "source": [
        "image_folder = 'plastic_dataset/plastic_images/plastic_images'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "vN_-PS-9SeRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e7502b-fdba-4aa4-a28e-23a080d89fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000047_gvtD3ib7.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000064_BTTPGrYi.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000045_PhlFazHo.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000014_0ZQvgsAb.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000068_UNZOfV6a.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000041_4WPTKNjc.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000011_ivDUJgCA.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000069_Ig1O3gD6.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000049_kpGAfuhx.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000065_NRkSZPKR.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000036_dRmEoXEM.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000056_rlY65QjG.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000051_Pejn1hn6.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000021_zV4DE7hY.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000040_JdwIj3QC.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000029_EYLTs3Rw.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000043_SrWFpmle.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000013_rJUVky4O.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000002_Cbz9fzUQ.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000010_TleUeK2v.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000061_z1ngjdlz.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000018_GoOCYIVN.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000007_FplCVcaI.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000028_QhB6eYcQ.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000031_GyvGmqct.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000035_ZTa940zI.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000001_Lg2XuAEB.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000016_ceTnQFul.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000060_AXkoooRY.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000009_sQWHZRn1.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000019_KYmVNl3T.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000044_yNGPwH4G.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000053_P5HeojNb.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000030_w6f4yUiS.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000062_dk7BmLef.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000004_ucYMNdCT.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000027_N8ftvaPG.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000059_T6BvlKYM.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000008_yoLvadEZ.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000022_egKBsm2a.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000024_6R4Yqe4X.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000023_SgXjxffS.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000057_1lgwf9Mp.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000003_kHaW3seo.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000055_ereeVX0F.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000020_229SZgYm.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000050_aF8q3wlO.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000012_BinznEjq.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000005_cxRJgVYL.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000017_H6LwK62i.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000054_pxx8uqBA.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000063_NgZ1iA8a.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000033_sEot12In.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000037_EuO7DasC.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000025_RFAKG2Ce.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000026_Bi49EY8a.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/IMG_20250831_113700.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000052_GzL0izbV.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000066_qUqXEJ15.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000038_DV3CPm9d.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000034_yTc8ToTd.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000048_sj9L9MHu.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000042_Bd3i7kBE.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000067_QaCoPBKP.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000058_97bZTaKJ.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000039_NWmgtHn8.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000015_VFhQRsOV.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000046_mkdrsXaK.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000032_s7mONLIl.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000070_1Z74z0k5.jpg\n",
            "plastic_dataset/plastic_images/plastic_images/dc_plastic_000006_U0Lugg9c.jpg\n"
          ]
        }
      ],
      "source": [
        "for root, dirs, files in os.walk('plastic_dataset'):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg','.jpeg','.png')):\n",
        "            print(os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "DNzLTyjHOeGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cae65f7-0c74-4287-8830-4f8971aea3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 71\n",
            "First 5 images: ['dc_plastic_000047_gvtD3ib7.jpg', 'dc_plastic_000064_BTTPGrYi.jpg', 'dc_plastic_000045_PhlFazHo.jpg', 'dc_plastic_000014_0ZQvgsAb.jpg', 'dc_plastic_000068_UNZOfV6a.jpg']\n"
          ]
        }
      ],
      "source": [
        "image_folder = 'plastic_dataset/plastic_images/plastic_images'\n",
        "img_list = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
        "\n",
        "print(\"Total images:\", len(img_list))\n",
        "print(\"First 5 images:\", img_list[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "5EmhRttaTx_6"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "for i in range(5):\n",
        "    img_path = os.path.join(image_folder, img_list[i])\n",
        "    img = Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "ugPyAxTpTx9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0132d24-c47e-437e-82af-a65c5c36d5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total annotation files: 1\n",
            "First 5 annotation files: ['plastic_annotation']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "print(\"Total annotation files:\", len(annotation_files))\n",
        "print(\"First 5 annotation files:\", annotation_files[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "6zmtTuwoTx5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb4f428-6e42-4e30-9f3e-1eb0d2fe39fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total annotation files: 70\n",
            "First 5 annotation files: ['dc_plastic_000025_RFAKG2Ce.xml', 'dc_plastic_000057_1lgwf9Mp.xml', 'dc_plastic_000051_Pejn1hn6.xml', 'dc_plastic_000034_yTc8ToTd.xml', 'dc_plastic_000031_GyvGmqct.xml']\n",
            "<annotation>\n",
            "  <folder>dc</folder>\n",
            "  <filename>dc_plastic_000025_RFAKG2Ce.jpg</filename>\n",
            "  <source>\n",
            "    <database>Unknown</database>\n",
            "    <annotation>Unknown</annotation>\n",
            "    <image>Unknown</image>\n",
            "  </source>\n",
            "  <size>\n",
            "    <width>2448</width>\n",
            "    <height>3264</height>\n",
            "    <depth></depth>\n",
            "  </size>\n",
            "  <segmented>0</segmented>\n",
            "  <object>\n",
            "    <name>plastic</name>\n",
            "    <truncated>0</truncated>\n",
            "    <occluded>0</occluded>\n",
            "    <difficult>0</difficult>\n",
            "    <bndbox>\n",
            "      <xmin>903.36</xmin>\n",
            "      <ymin>627\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "\n",
        "print(\"Total annotation files:\", len(annotation_files))\n",
        "print(\"First 5 annotation files:\", annotation_files[:5])\n",
        "\n",
        "file_path = os.path.join(annotation_folder, annotation_files[0])\n",
        "with open(file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(data[:500])  # Print first 500 characters to inspect the structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "w6FpNyikTx3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb32b2e4-282d-405c-c089-e135a5b2f811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filename: dc_plastic_000025_RFAKG2Ce.jpg, Label: plastic, BoundingBox: (903.36, 627.16), (2094.9, 1741.83)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "\n",
        "# Example: Parse first annotation file\n",
        "file_path = os.path.join(annotation_folder, annotation_files[0])\n",
        "tree = ET.parse(file_path)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Get image filename\n",
        "filename = root.find('filename').text\n",
        "\n",
        "# Get object details\n",
        "for obj in root.findall('object'):\n",
        "    label = obj.find('name').text\n",
        "    bndbox = obj.find('bndbox')\n",
        "    xmin = float(bndbox.find('xmin').text)\n",
        "    ymin = float(bndbox.find('ymin').text)\n",
        "    xmax = float(bndbox.find('xmax').text) if bndbox.find('xmax') is not None else None\n",
        "    ymax = float(bndbox.find('ymax').text) if bndbox.find('ymax') is not None else None\n",
        "    print(f\"Filename: {filename}, Label: {label}, BoundingBox: ({xmin}, {ymin}), ({xmax}, {ymax})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "n5mdth9OTxz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98bac9e-dcf4-45f4-de5a-4b401f275501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         filename    label     xmin    ymin     xmax     ymax\n",
            "0  dc_plastic_000025_RFAKG2Ce.jpg  plastic   903.36  627.16  2094.90  1741.83\n",
            "1  dc_plastic_000057_1lgwf9Mp.jpg  plastic  1008.40  878.30  1892.15  2345.25\n",
            "2  dc_plastic_000051_Pejn1hn6.jpg  plastic   503.18  547.98  1761.71  2406.12\n",
            "3  dc_plastic_000034_yTc8ToTd.jpg  plastic   553.72  891.51  2352.56  2747.32\n",
            "4  dc_plastic_000031_GyvGmqct.jpg  plastic   404.46  860.40  2389.50  3008.07\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "\n",
        "data_list = []\n",
        "\n",
        "for ann_file in annotation_files:\n",
        "    file_path = os.path.join(annotation_folder, ann_file)\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    filename = root.find('filename').text\n",
        "    for obj in root.findall('object'):\n",
        "        label = obj.find('name').text\n",
        "        bndbox = obj.find('bndbox')\n",
        "        xmin = float(bndbox.find('xmin').text)\n",
        "        ymin = float(bndbox.find('ymin').text)\n",
        "        xmax = float(bndbox.find('xmax').text) if bndbox.find('xmax') is not None else None\n",
        "        ymax = float(bndbox.find('ymax').text) if bndbox.find('ymax') is not None else None\n",
        "        data_list.append([filename, label, xmin, ymin, xmax, ymax])\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data_list, columns=['filename', 'label', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "Gz4SXh3gTxxT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_folder = 'plastic_dataset/plastic_images/plastic_images'\n",
        "\n",
        "for i in range(5):  # Display first 5 images with bounding boxes\n",
        "    row = df.iloc[i]\n",
        "    img_path = os.path.join(image_folder, row['filename'])\n",
        "    img = Image.open(img_path)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # Draw box\n",
        "    draw.rectangle([row['xmin'], row['ymin'], row['xmax'], row['ymax']], outline='red', width=3)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Label: {row['label']}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "s29e66R3Txuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0182090-90eb-4a7b-b2b5-1571d3d0e6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 62\n",
            "Testing samples: 14\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split based on unique filenames to avoid data leakage\n",
        "unique_files = df['filename'].unique()\n",
        "train_files, test_files = train_test_split(unique_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create train and test DataFrame subsets\n",
        "train_df = df[df['filename'].isin(train_files)].reset_index(drop=True)\n",
        "test_df = df[df['filename'].isin(test_files)].reset_index(drop=True)\n",
        "\n",
        "print(\"Training samples:\", len(train_df))\n",
        "print(\"Testing samples:\", len(test_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "B5R7GcZNyjUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "88107fe7-f53c-47df-f601-389cbbdd5017"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Dataset.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset.zip' -> 'yolo_dataset/images/val/Dataset.zip'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3112149958.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Move uploaded files to validation images folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'yolo_dataset/images/val/{filename}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset.zip'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs('yolo_dataset/images/val', exist_ok=True)\n",
        "\n",
        "# Move uploaded files to validation images folder\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, f'yolo_dataset/images/val/{filename}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "nhl9SGdGTxk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1433df3d-02c0-4192-a581-9be669e80b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17564, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 17564 (delta 33), reused 7 (delta 7), pack-reused 17510 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17564/17564), 16.65 MiB | 15.53 MiB/s, done.\n",
            "Resolving deltas: 100% (12035/12035), done.\n",
            "/content/yolov5/yolov5/yolov5/yolov5/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.16.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.64 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (8.3.189)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (25.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (2.0.16)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gdown\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "file_id = \"18pI0FdziEH-pm-eyf49dbqI062OYwIrJ\"\n",
        "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output_zip = \"Dataset.zip\"\n",
        "\n",
        "gdown.download(download_url, output_zip, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(output_zip, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"plastic_dataset\")\n",
        "\n",
        "print(\"Dataset downloaded and extracted to 'plastic_dataset' folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKu4ESNN4m_M",
        "outputId": "d7aac485-4971-41e9-ee84-f288494300d8"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18pI0FdziEH-pm-eyf49dbqI062OYwIrJ\n",
            "From (redirected): https://drive.google.com/uc?id=18pI0FdziEH-pm-eyf49dbqI062OYwIrJ&confirm=t&uuid=a06c0c92-579b-4878-a2c5-d99f46f3e369\n",
            "To: /content/yolov5/yolov5/yolov5/yolov5/yolov5/Dataset.zip\n",
            "100%|██████████| 186M/186M [00:01<00:00, 101MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and extracted to 'plastic_dataset' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "yuSuTlDxTxiH"
      },
      "outputs": [],
      "source": [
        "custom_data = \"\"\"\n",
        "train: ../yolo_dataset/images/train\n",
        "val: ../yolo_dataset/images/val\n",
        "\n",
        "nc: 1\n",
        "names: ['plastic']\n",
        "\"\"\"\n",
        "\n",
        "with open('custom_data.yaml', 'w') as f:\n",
        "    f.write(custom_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def convert_to_yolo(df, img_folder, save_folder):\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    grouped = df.groupby('filename')\n",
        "    for filename, group in grouped:\n",
        "        img_path = os.path.join(img_folder, filename)\n",
        "        img = Image.open(img_path)\n",
        "        img_width, img_height = img.size\n",
        "        txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
        "        txt_path = os.path.join(save_folder, txt_filename)\n",
        "\n",
        "        with open(txt_path, 'w') as f:\n",
        "            for _, row in group.iterrows():\n",
        "                x_center = ((row['xmin'] + row['xmax']) / 2) / img_width\n",
        "                y_center = ((row['ymin'] + row['ymax']) / 2) / img_height\n",
        "                width = (row['xmax'] - row['xmin']) / img_width\n",
        "                height = (row['ymax'] - row['ymin']) / img_height\n",
        "                f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")  # '0' is class index for plastic\n"
      ],
      "metadata": {
        "id": "J5ZXw8EMdutr"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Paths for label folders where YOLO txt labels will be saved\n",
        "label_train_folder = 'yolo_dataset/labels/train'\n",
        "label_val_folder = 'yolo_dataset/labels/val'\n",
        "\n",
        "# Paths for images copied into YOLOv5 format\n",
        "image_train_folder = 'yolo_dataset/images/train'\n",
        "image_val_folder = 'yolo_dataset/images/val'\n",
        "\n",
        "# Create all necessary directories if they don't exist\n",
        "os.makedirs(label_train_folder, exist_ok=True)\n",
        "os.makedirs(label_val_folder, exist_ok=True)\n",
        "os.makedirs(image_train_folder, exist_ok=True)\n",
        "os.makedirs(image_val_folder, exist_ok=True)\n",
        "\n",
        "print(f\"Directories ensured:\\n{label_train_folder}\\n{label_val_folder}\\n{image_train_folder}\\n{image_val_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWq0n_baduor",
        "outputId": "3e007329-f126-452c-82ef-14d46c224716"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories ensured:\n",
            "yolo_dataset/labels/train\n",
            "yolo_dataset/labels/val\n",
            "yolo_dataset/images/train\n",
            "yolo_dataset/images/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"yolo_dataset contents:\", os.listdir('yolo_dataset'))\n",
        "# If there are subfolders\n",
        "for root, dirs, files in os.walk('yolo_dataset'):\n",
        "    print(\"Root:\", root)\n",
        "    for d in dirs:\n",
        "        print(\" - Dir:\", d)\n",
        "    for f in files[:5]:  # Show sample files\n",
        "        print(\"   * File:\", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FToCpUfdukn",
        "outputId": "1aa8f8ba-b64a-489d-9590-7d31f6500232"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolo_dataset contents: ['labels', 'images']\n",
            "Root: yolo_dataset\n",
            " - Dir: labels\n",
            " - Dir: images\n",
            "Root: yolo_dataset/labels\n",
            " - Dir: val\n",
            " - Dir: train\n",
            "Root: yolo_dataset/labels/val\n",
            "Root: yolo_dataset/labels/train\n",
            "Root: yolo_dataset/images\n",
            " - Dir: val\n",
            " - Dir: train\n",
            "Root: yolo_dataset/images/val\n",
            "Root: yolo_dataset/images/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_train_folder = 'yolo_dataset/images/train'\n",
        "image_val_folder = 'yolo_dataset/images/val'\n",
        "label_train_folder = 'yolo_dataset/labels/train'\n",
        "label_val_folder = 'yolo_dataset/labels/val'\n"
      ],
      "metadata": {
        "id": "b2ze3nvOdug_"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get all present image filenames in train and val folders\n",
        "existing_train_images = set(os.listdir(image_train_folder))\n",
        "existing_val_images = set(os.listdir(image_val_folder))\n",
        "\n",
        "# Filter train/test df to only include images that exist in relevant folders\n",
        "filtered_train_df = train_df[train_df['filename'].isin(existing_train_images)].reset_index(drop=True)\n",
        "filtered_test_df = test_df[test_df['filename'].isin(existing_val_images)].reset_index(drop=True)\n",
        "\n",
        "# Convert only for images that are present\n",
        "convert_to_yolo(filtered_train_df, image_train_folder, label_train_folder)\n",
        "convert_to_yolo(filtered_test_df, image_val_folder, label_val_folder)"
      ],
      "metadata": {
        "id": "RvODqr2fg1Cj"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "original_image_folder = 'plastic_dataset/plastic_images/plastic_images'\n",
        "\n",
        "# Copy training images based on train_df (unfiltered)\n",
        "for img_file in train_df['filename'].unique():\n",
        "    src = os.path.join(original_image_folder, img_file)\n",
        "    dst = os.path.join('yolo_dataset/images/train', img_file)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "    else:\n",
        "        print(f\"Missing train file: {src}\")\n",
        "\n",
        "# Copy validation images based on test_df (unfiltered)\n",
        "for img_file in test_df['filename'].unique():\n",
        "    src = os.path.join(original_image_folder, img_file)\n",
        "    dst = os.path.join('yolo_dataset/images/val', img_file)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "    else:\n",
        "        print(f\"Missing val file: {src}\")\n"
      ],
      "metadata": {
        "id": "nI_ngvbrglM0"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train images after copy:\", os.listdir('yolo_dataset/images/train')[:5])\n",
        "print(\"Val images after copy:\", os.listdir('yolo_dataset/images/val')[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od_hqjaf2bYF",
        "outputId": "27b7316b-21c7-436f-b7a2-f0f7b218b6c9"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images after copy: ['dc_plastic_000047_gvtD3ib7.jpg', 'dc_plastic_000064_BTTPGrYi.jpg', 'dc_plastic_000045_PhlFazHo.jpg', 'dc_plastic_000014_0ZQvgsAb.jpg', 'dc_plastic_000068_UNZOfV6a.jpg']\n",
            "Val images after copy: ['dc_plastic_000041_4WPTKNjc.jpg', 'dc_plastic_000043_SrWFpmle.jpg', 'dc_plastic_000002_Cbz9fzUQ.jpg', 'dc_plastic_000018_GoOCYIVN.jpg', 'dc_plastic_000031_GyvGmqct.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "custom_data = \"\"\"\n",
        "train: yolo_dataset/images/train\n",
        "val: yolo_dataset/images/val\n",
        "nc: 1\n",
        "names: ['plastic']\n",
        "\"\"\"\n",
        "with open('custom_data.yaml', 'w') as f:\n",
        "    f.write(custom_data)"
      ],
      "metadata": {
        "id": "SbXj1-Cr2bMm"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_yolo(train_df, original_image_folder, 'yolo_dataset/labels/train')\n",
        "convert_to_yolo(test_df, original_image_folder, 'yolo_dataset/labels/val')\n"
      ],
      "metadata": {
        "id": "Z0g5svQq5fxJ"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Train labels files:\", os.listdir('yolo_dataset/labels/train')[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbBN7QyY5ZIi",
        "outputId": "e7c7d801-b3f9-40b0-b9ee-3338c7076d6b"
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train labels files: ['dc_plastic_000012_BinznEjq.txt', 'dc_plastic_000045_PhlFazHo.txt', 'dc_plastic_000010_TleUeK2v.txt', 'dc_plastic_000016_ceTnQFul.txt', 'dc_plastic_000029_EYLTs3Rw.txt', 'dc_plastic_000067_QaCoPBKP.txt', 'dc_plastic_000004_ucYMNdCT.txt', 'dc_plastic_000008_yoLvadEZ.txt', 'dc_plastic_000046_mkdrsXaK.txt', 'dc_plastic_000052_GzL0izbV.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 30 --data custom_data.yaml --weights yolov5s.pt --cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2-i67FMkCcu",
        "outputId": "b3aa7dda-8d91-4fe5-83ca-28791e87f5d2"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2025-08-31 16:12:00.342134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756656720.366567   94629 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756656720.373636   94629 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756656720.391798   94629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756656720.391841   94629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756656720.391848   94629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756656720.391852   94629 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-430-g459d8bf0 Python-3.12.11 torch-2.8.0+cu126 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/labels/train... 56 images, 0 backgrounds, 6 corrupt: 100% 56/56 [00:00<00:00, 675.11it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/train/dc_plastic_000019_KYmVNl3T.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0843]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/train/dc_plastic_000022_egKBsm2a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.314]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/train/dc_plastic_000024_6R4Yqe4X.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1871]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/train/dc_plastic_000038_DV3CPm9d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2597]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/train/dc_plastic_000039_NWmgtHn8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1079]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/train/dc_plastic_000042_Bd3i7kBE.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2088]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 50/50 [00:05<00:00,  9.50it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/labels/val... 14 images, 0 backgrounds, 3 corrupt: 100% 14/14 [00:01<00:00, 13.57it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000018_GoOCYIVN.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0625]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000031_GyvGmqct.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000032_s7mONLIl.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1247]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000044_yNGPwH4G.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2678]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 11/11 [00:01<00:00,  6.41it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.69 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp3/labels.jpg... \n",
            "/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:357: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/29         0G     0.1259    0.03398          0         45        640:  25% 1/4 [00:41<02:03, 41.18s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/29         0G     0.1255    0.03227          0         33        640:  50% 2/4 [01:10<01:08, 34.21s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/29         0G     0.1285    0.03163          0         39        640:  75% 3/4 [01:37<00:31, 31.06s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/29         0G      0.117    0.03034          0          3        640: 100% 4/4 [01:40<00:00, 25.20s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.46s/it]\n",
            "                   all         11         11    0.00333      0.182    0.00284   0.000568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       1/29         0G    0.08254    0.02868          0         33        640:  25% 1/4 [00:26<01:19, 26.53s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       1/29         0G     0.1034    0.03014          0         44        640:  50% 2/4 [00:53<00:53, 26.68s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       1/29         0G     0.1104    0.03059          0         40        640:  75% 3/4 [01:17<00:25, 25.65s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       1/29         0G     0.1037    0.03011          0          4        640: 100% 4/4 [01:21<00:00, 20.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.08s/it]\n",
            "                   all         11         11    0.00167     0.0909    0.00154   0.000463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       2/29         0G      0.118    0.03218          0         43        640:  25% 1/4 [00:25<01:17, 25.79s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       2/29         0G     0.1169    0.03081          0         37        640:  50% 2/4 [00:51<00:51, 25.68s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       2/29         0G     0.1152    0.03162          0         51        640:  75% 3/4 [01:16<00:25, 25.35s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       2/29         0G     0.1123    0.03164          0          6        640: 100% 4/4 [01:19<00:00, 19.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.92s/it]\n",
            "                   all         11         11    0.00333      0.182    0.00266   0.000996\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       3/29         0G     0.1291    0.03158          0         46        640:  25% 1/4 [00:26<01:18, 26.33s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       3/29         0G     0.1231    0.03072          0         42        640:  50% 2/4 [00:51<00:50, 25.47s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       3/29         0G     0.1174    0.02984          0         38        640:  75% 3/4 [01:16<00:25, 25.20s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       3/29         0G     0.1057    0.03088          0          7        640: 100% 4/4 [01:19<00:00, 19.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.99s/it]\n",
            "                   all         11         11    0.00333      0.273    0.00775    0.00242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       4/29         0G     0.1147    0.03008          0         46        640:  25% 1/4 [00:25<01:17, 25.85s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       4/29         0G     0.1097    0.02932          0         38        640:  50% 2/4 [00:51<00:51, 25.68s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       4/29         0G     0.1093    0.03045          0         51        640:  75% 3/4 [01:17<00:25, 25.93s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       4/29         0G    0.09707    0.03299          0          7        640: 100% 4/4 [01:20<00:00, 20.15s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.53s/it]\n",
            "                   all         11         11    0.00333      0.273     0.0495    0.00605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       5/29         0G     0.1141    0.03159          0         47        640:  25% 1/4 [00:25<01:17, 25.90s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       5/29         0G     0.1138    0.02999          0         45        640:  50% 2/4 [00:50<00:50, 25.12s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       5/29         0G     0.1096    0.03036          0         47        640:  75% 3/4 [01:17<00:25, 25.88s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       5/29         0G     0.1037    0.03271          0          8        640: 100% 4/4 [01:20<00:00, 20.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.87s/it]\n",
            "                   all         11         11    0.00333      0.273      0.031    0.00492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       6/29         0G     0.1092    0.03091          0         50        640:  25% 1/4 [00:25<01:17, 25.86s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       6/29         0G     0.1014    0.02842          0         33        640:  50% 2/4 [00:50<00:50, 25.06s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       6/29         0G    0.08919    0.02727          0         37        640:  75% 3/4 [01:18<00:26, 26.28s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       6/29         0G    0.08207    0.02777          0          5        640: 100% 4/4 [01:21<00:00, 20.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.84s/it]\n",
            "                   all         11         11    0.00333      0.364      0.016    0.00592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       7/29         0G    0.09423    0.02983          0         49        640:  25% 1/4 [00:26<01:20, 26.70s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       7/29         0G    0.09054    0.03017          0         45        640:  50% 2/4 [00:51<00:51, 25.74s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       7/29         0G    0.07848    0.02945          0         37        640:  75% 3/4 [01:18<00:26, 26.13s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       7/29         0G     0.0789    0.02936          0          6        640: 100% 4/4 [01:21<00:00, 20.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.75s/it]\n",
            "                   all         11         11    0.00333      0.545     0.0195    0.00634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       8/29         0G    0.08298    0.03134          0         46        640:  25% 1/4 [00:25<01:17, 25.81s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       8/29         0G     0.0691    0.02944          0         42        640:  50% 2/4 [00:51<00:51, 25.53s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       8/29         0G     0.0757    0.02952          0         45        640:  75% 3/4 [01:17<00:25, 25.68s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       8/29         0G    0.08104    0.02979          0         10        640: 100% 4/4 [01:19<00:00, 19.94s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.81s/it]\n",
            "                   all         11         11     0.0352      0.273     0.0515     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       9/29         0G    0.08858    0.03016          0         44        640:  25% 1/4 [00:24<01:14, 24.76s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       9/29         0G    0.08492    0.02877          0         43        640:  50% 2/4 [00:49<00:49, 24.83s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       9/29         0G    0.08635    0.02936          0         52        640:  75% 3/4 [01:15<00:25, 25.24s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       9/29         0G    0.07072    0.02561          0          2        640: 100% 4/4 [01:18<00:00, 19.69s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:05<00:00,  5.31s/it]\n",
            "                   all         11         11      0.202      0.273       0.26     0.0461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      10/29         0G    0.07265    0.03081          0         47        640:  25% 1/4 [00:25<01:16, 25.35s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      10/29         0G    0.07679    0.03273          0         58        640:  50% 2/4 [00:50<00:50, 25.11s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      10/29         0G     0.0781    0.03108          0         41        640:  75% 3/4 [01:15<00:25, 25.11s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      10/29         0G    0.06719    0.02911          0          4        640: 100% 4/4 [01:18<00:00, 19.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/1 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 1.050s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.78s/it]\n",
            "                   all         11         11      0.138     0.0909      0.238     0.0757\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      11/29         0G      0.082    0.03065          0         47        640:  25% 1/4 [00:25<01:17, 25.99s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      11/29         0G    0.07511    0.03126          0         49        640:  50% 2/4 [00:51<00:51, 25.74s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      11/29         0G    0.07421    0.02861          0         37        640:  75% 3/4 [01:17<00:25, 25.97s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      11/29         0G    0.07677    0.03029          0          8        640: 100% 4/4 [01:21<00:00, 20.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:04<00:00,  4.78s/it]\n",
            "                   all         11         11      0.185      0.273      0.287     0.0941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "  0% 0/4 [00:00<?, ?it/s]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      12/29         0G    0.06989    0.02491          0         36        640:  25% 1/4 [00:25<01:17, 25.81s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "      12/29         0G    0.06239     0.0243          0         35        640:  50% 2/4 [00:51<00:51, 25.80s/it]/content/yolov5/yolov5/yolov5/yolov5/yolov5/train.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp3/weights/best.pt --img 640 --conf 0.10 --source yolo_dataset/images/val --project runs/detect --name val_results --exist-ok\n"
      ],
      "metadata": {
        "id": "lcKOE-OIt3r2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3bb268-7bfa-422e-dd95-ec6e3245f7db"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp3/weights/best.pt'], source=yolo_dataset/images/val, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=val_results, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-430-g459d8bf0 Python-3.12.11 torch-2.8.0+cu126 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000001_Lg2XuAEB.jpg: 640x480 2 plastics, 320.6ms\n",
            "image 2/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000002_Cbz9fzUQ.jpg: 640x288 1 plastic, 184.9ms\n",
            "image 3/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000018_GoOCYIVN.jpg: 640x480 5 plastics, 294.8ms\n",
            "image 4/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000025_RFAKG2Ce.jpg: 640x480 1 plastic, 295.5ms\n",
            "image 5/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000026_Bi49EY8a.jpg: 640x480 3 plastics, 293.1ms\n",
            "image 6/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000027_N8ftvaPG.jpg: 640x480 2 plastics, 296.0ms\n",
            "image 7/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000031_GyvGmqct.jpg: 640x480 1 plastic, 280.1ms\n",
            "image 8/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000032_s7mONLIl.jpg: 640x480 (no detections), 312.8ms\n",
            "image 9/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000035_ZTa940zI.jpg: 640x480 3 plastics, 277.2ms\n",
            "image 10/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000041_4WPTKNjc.jpg: 640x480 (no detections), 280.6ms\n",
            "image 11/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000043_SrWFpmle.jpg: 640x480 (no detections), 295.5ms\n",
            "image 12/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000044_yNGPwH4G.jpg: 640x480 1 plastic, 291.6ms\n",
            "image 13/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000058_97bZTaKJ.jpg: 640x480 (no detections), 275.4ms\n",
            "image 14/14 /content/yolov5/yolov5/yolov5/yolov5/yolov5/yolo_dataset/images/val/dc_plastic_000059_T6BvlKYM.jpg: 640x480 2 plastics, 282.7ms\n",
            "Speed: 1.6ms pre-process, 284.3ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/val_results\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "results_folder = 'runs/detect/val_results'\n",
        "images = [f for f in os.listdir(results_folder) if f.endswith('.jpg')]\n",
        "\n",
        "for image in images[:5]:\n",
        "    img_path = os.path.join(results_folder, image)\n",
        "    img = Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(image)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "bXmIGG5ukCPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Load your trained YOLOv5 model (adjust the path to your weights file)\n",
        "model = torch.hub.load(\"ultralytics/yolov5\", \"custom\", path=\"runs/train/exp3/weights/best.pt\", force_reload=True)\n",
        "\n",
        "# Create a file upload widget that accepts image files\n",
        "upload_widget = widgets.FileUpload(accept='image/*', multiple=False)\n",
        "\n",
        "def on_upload_change(change):\n",
        "    clear_output(wait=True)\n",
        "    for name, file_info in upload_widget.value.items():\n",
        "        img_bytes = file_info['content']\n",
        "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "\n",
        "        # Display uploaded image resized\n",
        "        img_resized = img.resize((480, 480))\n",
        "        display(img_resized)\n",
        "\n",
        "        # Run inference\n",
        "        results = model(img)\n",
        "\n",
        "        # Get detection results as PIL image\n",
        "        result_img = Image.fromarray(results.render()[0])\n",
        "\n",
        "        # Resize detection output for display\n",
        "        result_resized = result_img.resize((480, 480))\n",
        "        display(result_resized)\n",
        "\n",
        "        # If no detections, print message\n",
        "        if len(results.xyxy[0]) == 0:\n",
        "            print(\"No objects detected. Try uploading an image with plastic objects similar to the training data.\")\n",
        "\n",
        "\n",
        "\n",
        "# Set the function to trigger upon file upload\n",
        "upload_widget.observe(on_upload_change, names='value')\n",
        "\n",
        "# Display instructions and the upload widget\n",
        "display(widgets.HTML(\"<h2>Upload an image to detect plastic waste</h2>\"))\n",
        "display(upload_widget)\n"
      ],
      "metadata": {
        "id": "SYKwFklssahh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5L_6Y6-saat"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbShqpTnz4jly9KST/a5Iw"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}