{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chethan-Kumar9845/Plastic-Waste-Detection/blob/main/Plastic_Waste_Detection_Using_Image_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq8YSNO7MRhP"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gdown\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "file_id = \"18pI0FdziEH-pm-eyf49dbqI062OYwIrJ\"\n",
        "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output_zip = \"Dataset.zip\"\n",
        "\n",
        "gdown.download(download_url, output_zip, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(output_zip, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"plastic_dataset\")\n",
        "\n",
        "print(\"Dataset downloaded and extracted to 'plastic_dataset' folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9UTWyplSeZh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# List all items (including folders and files) in plastic_dataset\n",
        "print(\"plastic_dataset contents:\", os.listdir('plastic_dataset'))\n",
        "\n",
        "# List all items in plastic_images (should show your files/folders)\n",
        "print(\"plastic_images contents:\", os.listdir('plastic_dataset/plastic_images'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMr46SSfSeV-"
      },
      "outputs": [],
      "source": [
        "image_folder = 'plastic_dataset/plastic_images/plastic_images'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN_-PS-9SeRb"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk('plastic_dataset'):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg','.jpeg','.png')):\n",
        "            print(os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNzLTyjHOeGx"
      },
      "outputs": [],
      "source": [
        "image_folder = 'plastic_dataset/plastic_images/plastic_images'\n",
        "img_list = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
        "\n",
        "print(\"Total images:\", len(img_list))\n",
        "print(\"First 5 images:\", img_list[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EmhRttaTx_6"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "for i in range(5):\n",
        "    img_path = os.path.join(image_folder, img_list[i])\n",
        "    img = Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugPyAxTpTx9X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "print(\"Total annotation files:\", len(annotation_files))\n",
        "print(\"First 5 annotation files:\", annotation_files[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zmtTuwoTx5-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "\n",
        "print(\"Total annotation files:\", len(annotation_files))\n",
        "print(\"First 5 annotation files:\", annotation_files[:5])\n",
        "\n",
        "file_path = os.path.join(annotation_folder, annotation_files[0])\n",
        "with open(file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(data[:500])  # Print first 500 characters to inspect the structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6FpNyikTx3H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "\n",
        "# Example: Parse first annotation file\n",
        "file_path = os.path.join(annotation_folder, annotation_files[0])\n",
        "tree = ET.parse(file_path)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Get image filename\n",
        "filename = root.find('filename').text\n",
        "\n",
        "# Get object details\n",
        "for obj in root.findall('object'):\n",
        "    label = obj.find('name').text\n",
        "    bndbox = obj.find('bndbox')\n",
        "    xmin = float(bndbox.find('xmin').text)\n",
        "    ymin = float(bndbox.find('ymin').text)\n",
        "    xmax = float(bndbox.find('xmax').text) if bndbox.find('xmax') is not None else None\n",
        "    ymax = float(bndbox.find('ymax').text) if bndbox.find('ymax') is not None else None\n",
        "    print(f\"Filename: {filename}, Label: {label}, BoundingBox: ({xmin}, {ymin}), ({xmax}, {ymax})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5mdth9OTxz9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "annotation_folder = 'plastic_dataset/plastic_annotation/plastic_annotation'\n",
        "annotation_files = os.listdir(annotation_folder)\n",
        "\n",
        "data_list = []\n",
        "\n",
        "for ann_file in annotation_files:\n",
        "    file_path = os.path.join(annotation_folder, ann_file)\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    filename = root.find('filename').text\n",
        "    for obj in root.findall('object'):\n",
        "        label = obj.find('name').text\n",
        "        bndbox = obj.find('bndbox')\n",
        "        xmin = float(bndbox.find('xmin').text)\n",
        "        ymin = float(bndbox.find('ymin').text)\n",
        "        xmax = float(bndbox.find('xmax').text) if bndbox.find('xmax') is not None else None\n",
        "        ymax = float(bndbox.find('ymax').text) if bndbox.find('ymax') is not None else None\n",
        "        data_list.append([filename, label, xmin, ymin, xmax, ymax])\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data_list, columns=['filename', 'label', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz4SXh3gTxxT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_folder = 'plastic_dataset/plastic_images/plastic_images'\n",
        "\n",
        "for i in range(5):  # Display first 5 images with bounding boxes\n",
        "    row = df.iloc[i]\n",
        "    img_path = os.path.join(image_folder, row['filename'])\n",
        "    img = Image.open(img_path)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # Draw box\n",
        "    draw.rectangle([row['xmin'], row['ymin'], row['xmax'], row['ymax']], outline='red', width=3)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Label: {row['label']}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s29e66R3Txuz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split based on unique filenames to avoid data leakage\n",
        "unique_files = df['filename'].unique()\n",
        "train_files, test_files = train_test_split(unique_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create train and test DataFrame subsets\n",
        "train_df = df[df['filename'].isin(train_files)].reset_index(drop=True)\n",
        "test_df = df[df['filename'].isin(test_files)].reset_index(drop=True)\n",
        "\n",
        "print(\"Training samples:\", len(train_df))\n",
        "print(\"Testing samples:\", len(test_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui0Dg8_MTxoi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5R7GcZNyjUK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs('yolo_dataset/images/val', exist_ok=True)\n",
        "\n",
        "# Move uploaded files to validation images folder\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, f'yolo_dataset/images/val/{filename}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhl9SGdGTxk4"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuSuTlDxTxiH"
      },
      "outputs": [],
      "source": [
        "custom_data = \"\"\"\n",
        "train: ../yolo_dataset/images/train\n",
        "val: ../yolo_dataset/images/val\n",
        "\n",
        "nc: 1\n",
        "names: ['plastic']\n",
        "\"\"\"\n",
        "\n",
        "with open('custom_data.yaml', 'w') as f:\n",
        "    f.write(custom_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def convert_to_yolo(df, img_folder, save_folder):\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    grouped = df.groupby('filename')\n",
        "    for filename, group in grouped:\n",
        "        img_path = os.path.join(img_folder, filename)\n",
        "        img = Image.open(img_path)\n",
        "        img_width, img_height = img.size\n",
        "        txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
        "        txt_path = os.path.join(save_folder, txt_filename)\n",
        "\n",
        "        with open(txt_path, 'w') as f:\n",
        "            for _, row in group.iterrows():\n",
        "                x_center = ((row['xmin'] + row['xmax']) / 2) / img_width\n",
        "                y_center = ((row['ymin'] + row['ymax']) / 2) / img_height\n",
        "                width = (row['xmax'] - row['xmin']) / img_width\n",
        "                height = (row['ymax'] - row['ymin']) / img_height\n",
        "                f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")  # '0' is class index for plastic\n"
      ],
      "metadata": {
        "id": "J5ZXw8EMdutr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paths for label folders where YOLO txt labels will be saved\n",
        "label_train_folder = 'yolo_dataset/labels/train'\n",
        "label_val_folder = 'yolo_dataset/labels/val'\n",
        "\n",
        "# Paths for images copied into YOLOv5 format\n",
        "image_train_folder = 'yolo_dataset/images/train'\n",
        "image_val_folder = 'yolo_dataset/images/val'\n",
        "\n",
        "# Create all necessary directories if they don't exist\n",
        "os.makedirs(label_train_folder, exist_ok=True)\n",
        "os.makedirs(label_val_folder, exist_ok=True)\n",
        "os.makedirs(image_train_folder, exist_ok=True)\n",
        "os.makedirs(image_val_folder, exist_ok=True)\n",
        "\n",
        "print(f\"Directories ensured:\\n{label_train_folder}\\n{label_val_folder}\\n{image_train_folder}\\n{image_val_folder}\")\n"
      ],
      "metadata": {
        "id": "CWq0n_baduor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"yolo_dataset contents:\", os.listdir('yolo_dataset'))\n",
        "# If there are subfolders\n",
        "for root, dirs, files in os.walk('yolo_dataset'):\n",
        "    print(\"Root:\", root)\n",
        "    for d in dirs:\n",
        "        print(\" - Dir:\", d)\n",
        "    for f in files[:5]:  # Show sample files\n",
        "        print(\"   * File:\", f)\n"
      ],
      "metadata": {
        "id": "4FToCpUfdukn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_train_folder = 'yolo_dataset/images/train'\n",
        "image_val_folder = 'yolo_dataset/images/val'\n",
        "label_train_folder = 'yolo_dataset/labels/train'\n",
        "label_val_folder = 'yolo_dataset/labels/val'\n"
      ],
      "metadata": {
        "id": "b2ze3nvOdug_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get all present image filenames in train and val folders\n",
        "existing_train_images = set(os.listdir(image_train_folder))\n",
        "existing_val_images = set(os.listdir(image_val_folder))\n",
        "\n",
        "# Filter train/test df to only include images that exist in relevant folders\n",
        "filtered_train_df = train_df[train_df['filename'].isin(existing_train_images)].reset_index(drop=True)\n",
        "filtered_test_df = test_df[test_df['filename'].isin(existing_val_images)].reset_index(drop=True)\n",
        "\n",
        "# Convert only for images that are present\n",
        "convert_to_yolo(filtered_train_df, image_train_folder, label_train_folder)\n",
        "convert_to_yolo(filtered_test_df, image_val_folder, label_val_folder)\n"
      ],
      "metadata": {
        "id": "RvODqr2fg1Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_yolo(filtered_train_df, image_train_folder, label_train_folder)\n",
        "convert_to_yolo(filtered_test_df, image_val_folder, label_val_folder)\n"
      ],
      "metadata": {
        "id": "JK4OgAwYglQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "original_image_folder = 'plastic_dataset/plastic_images/plastic_images'\n",
        "\n",
        "# Copy training images based on train_df (unfiltered)\n",
        "for img_file in train_df['filename'].unique():\n",
        "    src = os.path.join(original_image_folder, img_file)\n",
        "    dst = os.path.join('yolo_dataset/images/train', img_file)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "    else:\n",
        "        print(f\"Missing train file: {src}\")\n",
        "\n",
        "# Copy validation images based on test_df (unfiltered)\n",
        "for img_file in test_df['filename'].unique():\n",
        "    src = os.path.join(original_image_folder, img_file)\n",
        "    dst = os.path.join('yolo_dataset/images/val', img_file)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "    else:\n",
        "        print(f\"Missing val file: {src}\")\n"
      ],
      "metadata": {
        "id": "nI_ngvbrglM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train images after copy:\", os.listdir('yolo_dataset/images/train')[:5])\n",
        "print(\"Val images after copy:\", os.listdir('yolo_dataset/images/val')[:5])\n"
      ],
      "metadata": {
        "id": "HXbZo2ZMh7X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_yolo(train_df, original_image_folder, label_train_folder)\n",
        "convert_to_yolo(test_df, original_image_folder, label_val_folder)\n"
      ],
      "metadata": {
        "id": "VE_XXmJHglJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train images:\", os.listdir('yolo_dataset/images/train'))\n",
        "print(\"Val images:\", os.listdir('yolo_dataset/images/val'))\n"
      ],
      "metadata": {
        "id": "N-tMBAQ7i9yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_data = \"\"\"\n",
        "train: yolo_dataset/images/train\n",
        "val: yolo_dataset/images/val\n",
        "nc: 1\n",
        "names: ['plastic']\n",
        "\"\"\"\n",
        "with open('custom_data.yaml', 'w') as f:\n",
        "    f.write(custom_data)\n"
      ],
      "metadata": {
        "id": "16kysG5ai9rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 20 --data custom_data.yaml --weights yolov5s.pt --cache\n"
      ],
      "metadata": {
        "id": "Q2-i67FMkCcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp3/weights/best.pt --img 640 --conf 0.12 --source yolo_dataset/images/val --project runs/detect --name val_results --exist-ok\n"
      ],
      "metadata": {
        "id": "lcKOE-OIt3r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "results_folder = 'runs/detect/val_results'\n",
        "images = [f for f in os.listdir(results_folder) if f.endswith('.jpg')]\n",
        "\n",
        "for image in images[:5]:\n",
        "    img_path = os.path.join(results_folder, image)\n",
        "    img = Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(image)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "bXmIGG5ukCPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Load your trained YOLOv5 model (adjust the path to your weights file)\n",
        "model = torch.hub.load(\"ultralytics/yolov5\", \"custom\", path=\"runs/train/exp3/weights/best.pt\", force_reload=True)\n",
        "\n",
        "# Create a file upload widget that accepts image files\n",
        "upload_widget = widgets.FileUpload(accept='image/*', multiple=False)\n",
        "\n",
        "def on_upload_change(change):\n",
        "    clear_output(wait=True)\n",
        "    for name, file_info in upload_widget.value.items():\n",
        "        img_bytes = file_info['content']\n",
        "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "\n",
        "        # Display uploaded image resized\n",
        "        img_resized = img.resize((480, 480))\n",
        "        display(img_resized)\n",
        "\n",
        "        # Run inference\n",
        "        results = model(img)\n",
        "\n",
        "        # Get detection results as PIL image\n",
        "        result_img = Image.fromarray(results.render()[0])\n",
        "\n",
        "        # Resize detection output for display\n",
        "        result_resized = result_img.resize((480, 480))\n",
        "        display(result_resized)\n",
        "\n",
        "        # If no detections, print message\n",
        "        if len(results.xyxy[0]) == 0:\n",
        "            print(\"No objects detected. Try uploading an image with plastic objects similar to the training data.\")\n",
        "\n",
        "\n",
        "\n",
        "# Set the function to trigger upon file upload\n",
        "upload_widget.observe(on_upload_change, names='value')\n",
        "\n",
        "# Display instructions and the upload widget\n",
        "display(widgets.HTML(\"<h2>Upload an image to detect plastic waste</h2>\"))\n",
        "display(upload_widget)\n"
      ],
      "metadata": {
        "id": "SYKwFklssahh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5L_6Y6-saat"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPbkTRgac/Xsf72HAdv0Z+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}